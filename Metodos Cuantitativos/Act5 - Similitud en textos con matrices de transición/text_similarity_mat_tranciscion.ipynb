{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rafael Hinojosa López\n",
    "\n",
    "A01705777\n",
    "\n",
    "28-05-2023\n",
    "\n",
    "Desarrollo de aplicaciones avanzadas de ciencias computacionales (Gpo 301)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./text_3.txt\", 'r', encoding='utf-8') as f:\n",
    "    text1 = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./text_4.txt\", 'r', encoding='utf-8') as f:\n",
    "    text2 = f.read()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocess text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'c', 'b', 'a', 'd', 'c', 'b', 'a', 'c', 'a', 'b', 'd', 'b', 'a', 'b']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = text1.lower()\n",
    "text2 = text2.lower()\n",
    "\n",
    "text1 = re.findall(r\"[A-Za-z=+-/!*]+|\\w+\", text1)\n",
    "text2 = re.findall(r\"[A-Za-z=+-/!*]+|\\w+\", text2)\n",
    "\n",
    "combined_text = text1 + text2\n",
    "combined_text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Create one directed graph per text where vertex (key of the dict) _v_ represents a word in the text and contains a list of all the words that appear right after that word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': ['c', 'd'], 'c': ['b'], 'b': ['a'], 'd': ['c']}\n",
      "{'a': ['c', 'b', 'b'], 'c': ['a'], 'b': ['a', 'd', 'a'], 'd': ['b']}\n"
     ]
    }
   ],
   "source": [
    "words1 = {}\n",
    "words2 = {}\n",
    "\n",
    "for word in combined_text:\n",
    "    words1[word] = []\n",
    "    words2[word] = []\n",
    "\n",
    "# Create graph for text1\n",
    "for i in range(1, len(text1)):\n",
    "    origin_word = text1[i-1]\n",
    "    destination_word = text1[i]\n",
    "    words1[origin_word].append(destination_word)\n",
    "\n",
    "# Create graph for text2\n",
    "for i in range(1, len(text2)):\n",
    "    origin_word = text2[i-1]\n",
    "    destination_word = text2[i]\n",
    "    words2[origin_word].append(destination_word)\n",
    "    \n",
    "print(words1)\n",
    "print(words2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Crear un arreglo donde se mapeen las palabras con su posicion en el grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 0, 'c': 1, 'b': 2, 'd': 3}\n",
      "{'a': 0, 'c': 1, 'b': 2, 'd': 3}\n"
     ]
    }
   ],
   "source": [
    "words1_index = {}\n",
    "words2_index = {}\n",
    "\n",
    "index = 0\n",
    "for word in words1:\n",
    "    words1_index[word] = index\n",
    "    index += 1\n",
    "\n",
    "index = 0\n",
    "for word in words2:\n",
    "    words2_index[word] = index\n",
    "    index += 1\n",
    "\n",
    "print(words1_index)\n",
    "print(words2_index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Create transition matrices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- inicializar un array de length palabras con 0s\n",
    "- llenar las que ya se tienen guardadas en su indice correspondiente y ya!! hacer append de la lista a la matriz wuuu\n",
    "/ ok necesitamos que las matrices y asi... estar tratando con todas las palabras, no solo con las actuales...\n",
    "\n",
    "con esto ponemos ok... mat1[map[i]] = 1 / total o asi... o sea aja... \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  0.5 0.  0.5]\n",
      " [0.  0.  1.  0. ]\n",
      " [1.  0.  0.  0. ]\n",
      " [0.  1.  0.  0. ]]\n",
      "[[0.         0.33333333 0.66666667 0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.66666667 0.         0.         0.33333333]\n",
      " [0.         0.         1.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "mat1 = []\n",
    "mat2 = []\n",
    "\n",
    "len1 = len(words1)\n",
    "len2 = len(words2)\n",
    "\n",
    "for word in words1:\n",
    "    list1 = [0 for i in range(len1)]\n",
    "\n",
    "    val1 = 0\n",
    "    if len(words1[word]) != 0:\n",
    "        val1 = 1 / len(words1[word])\n",
    "\n",
    "    for next_word in words1[word]:\n",
    "        next_word_index = words1_index[next_word]\n",
    "        list1[next_word_index] += val1        \n",
    "\n",
    "    mat1.append(list1)\n",
    "\n",
    "\n",
    "for word in words2:\n",
    "    list2 = [0 for i in range(len2)]\n",
    "    \n",
    "    val2 = 0\n",
    "    if len(words2[word]) != 0:\n",
    "        val2 = 1 / len(words2[word])\n",
    "\n",
    "    for next_word in words2[word]:\n",
    "        next_word_index = words2_index[next_word]\n",
    "        list2[next_word_index] += val2        \n",
    "\n",
    "    mat2.append(list2)\n",
    "\n",
    "mat1 = np.array(mat1)\n",
    "mat2 = np.array(mat2)\n",
    "\n",
    "print(mat1)\n",
    "print(mat2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A | Mat1 = \n",
      "[[0.  0.5 0.  0.5]\n",
      " [0.  0.  1.  0. ]\n",
      " [1.  0.  0.  0. ]\n",
      " [0.  1.  0.  0. ]]\n",
      "\n",
      "B | Mat2 = \n",
      "[[0.         0.33333333 0.66666667 0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.66666667 0.         0.         0.33333333]\n",
      " [0.         0.         1.         0.        ]]\n",
      "\n",
      "BT | Transpose of Mat2 = \n",
      "[[0.         1.         0.66666667 0.        ]\n",
      " [0.33333333 0.         0.         0.        ]\n",
      " [0.66666667 0.         0.         1.        ]\n",
      " [0.         0.         0.33333333 0.        ]]\n",
      "\n",
      "C = [[0.66666667 0.         1.         0.        ]\n",
      " [0.         0.16666667 0.         0.16666667]\n",
      " [0.         1.33333333 0.         0.33333333]\n",
      " [0.33333333 0.         0.         0.        ]]\n",
      "\n",
      "Prod int = 0.8333\n",
      "\n",
      "Norm A | Norm Mat1 = 1.8708\n",
      "\n",
      "Norm B | Norm Mat2 = 1.7638\n",
      "\n",
      "Cosine angle = 0.2525\n",
      "\n",
      "The similarity of both texts is 25.25%, based on the cosine distance of transition matrices.\n"
     ]
    }
   ],
   "source": [
    "BT = mat2.transpose()\n",
    "C = np.matmul(BT, mat1)\n",
    "prod_int = np.trace(C)\n",
    "\n",
    "norm_A = math.sqrt(np.trace(np.matmul(mat1.transpose(), mat1)))\n",
    "norm_B = math.sqrt(np.trace(np.matmul(mat2.transpose(), mat2)))\n",
    "\n",
    "cos_ang = prod_int / (norm_A * norm_B)\n",
    "\n",
    "\n",
    "print('A | Mat1 = \\n' + str(mat1) + '\\n')\n",
    "print('B | Mat2 = \\n' + str(mat2) + '\\n')\n",
    "print('BT | Transpose of Mat2 = \\n' + str(BT) + '\\n')\n",
    "print('C = ' + str(C) + '\\n')\n",
    "print('Prod int = ' + str(round(prod_int, 4)) + '\\n')\n",
    "print('Norm A | Norm Mat1 = ' + str(round(norm_A, 4)) + '\\n')\n",
    "print('Norm B | Norm Mat2 = ' + str(round(norm_B, 4)) + '\\n')\n",
    "print('Cosine angle = ' + str(round(cos_ang, 4)) + '\\n')\n",
    "print('The similarity of both texts is ' + str(round(cos_ang, 4) * 100) + '%' + ', based on the cosine distance of transition matrices.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reflexiones"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Adecua tu programa para encontrar similitud entre dos códigos hechos en Python. ¿Qué preprocesamiento tendrías que hacer con los códigos antes de compararlos? (Por ejemplo, a = b + c y r = m + n se tomarían como completamente disintos. ¿Cómo podrías evitar eso?\n",
    "\n",
    "El programa fue adecuado para identificar símbolos que el lenguaje Python utiliza como: '+', '-', '/', '*', '=', '!'. A pesar de que parece que la solución será más precisa, no es así, ya que al no contar con un _lexer_ para tokenizar correctamente los símbolos y las palabras reservadas o variables que se tienen en el código, algunas palabras se mezclaron con los símbolos, lo cual hizo que la precisión con la que se calcula la distancia disminuya hasta en un 100% (en el extremo peor de los casos).\n",
    "\n",
    "Para evitar que _a = b + c_ y _r = m + n_ sean diferentes, es necesario tokenizar ambas expresiones para que, traducido sea: _variable = variable + variable_ en ambos casos. \n",
    "\n",
    "Esto implicaría implementar o utilizar un _lexer_ y _mapear_ las palabras con el tipo de expresiones que son en Python. Por ejemplo, en vez de guardar el nombre de una variable, guardar el nombre _variable_, con el fin de enfocarse en que la palabra en cuestión es una variable sin importar el nombre que le asignaron. \n",
    "\n",
    "Al tokenizar, podremos obtener la similitud que hay entre dos códigos con respecto al orden en el que los tokens aparecen en el código, suponiendo que utilizamos esta técnica de matrices de transición. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Realiza distintas pruebas con distintos códigos hechos en Python. ¿Crees que esta técnica es adecuada para encontrar la similitud entre códigos?¿Es más eficiente que la técnica de similitud por distribuciones de probabilidad?\n",
    "\n",
    "Tomando como ejemplo los archivos sol_1.txt y sol_2.txt, la similitud que obtenemos con ambas soluciones es la siguiente:\n",
    "- Similitud por matrices de transición = 20.6%\n",
    "- Similitud por distribuciones de probabilidad = 61.4%\n",
    "\n",
    "Se observa que la similitud calculada por distribuciones de probabilidad es ~3 veces más alta que aquella calculada por matrices de transición en este caso. Ambos métodos calculan la similitud de maneras diferentes: uno basado en qué tan parecidos son los textos con respecto a las palabras que contienen y su número de repeticiones (distribuciones de probabilidad); y el otro, basado en el orden de las palabras (matrices de transición). \n",
    "\n",
    "Una desventaja de este método en particular es que si el orden del código cambia, la similitud también puede cambiar o no ser completamente precisa (comparar sol_5.txt y sol_6.txt).\n",
    "\n",
    "Si se tokenizara el código correctamente, considero que ambos métodos pueden ser útiles para encontrar la similitud de dos códigos de Python. Si se quiere medir la similitud léxica, la distribución de probabilidad es la mejor opción; en cambio, si se quiere medir la similitud en el orden del código, la mejor opción es utilizar matrices de transición.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
