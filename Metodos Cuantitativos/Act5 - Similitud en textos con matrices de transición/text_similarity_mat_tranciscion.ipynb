{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rafael Hinojosa LÃ³pez\n",
    "\n",
    "A01705777\n",
    "\n",
    "28-05-2023\n",
    "\n",
    "Desarrollo de aplicaciones avanzadas de ciencias computacionales (Gpo 301)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./text1.txt\", 'r', encoding='utf-8') as f:\n",
    "    text1 = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./text2.txt\", 'r', encoding='utf-8') as f:\n",
    "    text2 = f.read()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocess text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'good',\n",
       " 'day',\n",
       " 'what',\n",
       " 'day',\n",
       " 'is',\n",
       " 'today',\n",
       " 'good',\n",
       " 'day',\n",
       " 'is',\n",
       " 'a',\n",
       " 'this',\n",
       " 'today',\n",
       " 'is',\n",
       " 'what',\n",
       " 'day']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = text1.lower()\n",
    "text2 = text2.lower()\n",
    "\n",
    "text1 = re.findall(r'\\w+', text1)\n",
    "text2 = re.findall(r'\\w+', text2)\n",
    "\n",
    "combined_text = text1 + text2\n",
    "combined_text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Create one directed graph per text where vertex (key of the dict) _v_ represents a word in the text and contains a list of all the words that appear right after that word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': ['is'], 'is': ['a', 'today'], 'a': ['good'], 'good': ['day'], 'day': ['what', 'is'], 'what': ['day'], 'today': []}\n",
      "{'this': ['today'], 'is': ['a', 'what'], 'a': ['this'], 'good': ['day'], 'day': ['is'], 'what': ['day'], 'today': ['is']}\n"
     ]
    }
   ],
   "source": [
    "words1 = {}\n",
    "words2 = {}\n",
    "\n",
    "for word in combined_text:\n",
    "    words1[word] = []\n",
    "    words2[word] = []\n",
    "\n",
    "# Create graph for text1\n",
    "for i in range(1, len(text1)):\n",
    "    origin_word = text1[i-1]\n",
    "    destination_word = text1[i]\n",
    "    words1[origin_word].append(destination_word)\n",
    "\n",
    "# Create graph for text2\n",
    "for i in range(1, len(text2)):\n",
    "    origin_word = text2[i-1]\n",
    "    destination_word = text2[i]\n",
    "    words2[origin_word].append(destination_word)\n",
    "    \n",
    "print(words1)\n",
    "print(words2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Crear un arreglo donde se mapeen las palabras con su posicion en el grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 0, 'is': 1, 'a': 2, 'good': 3, 'day': 4, 'what': 5, 'today': 6}\n",
      "{'this': 0, 'is': 1, 'a': 2, 'good': 3, 'day': 4, 'what': 5, 'today': 6}\n"
     ]
    }
   ],
   "source": [
    "words1_index = {}\n",
    "words2_index = {}\n",
    "\n",
    "index = 0\n",
    "for word in words1:\n",
    "    words1_index[word] = index\n",
    "    index += 1\n",
    "\n",
    "index = 0\n",
    "for word in words2:\n",
    "    words2_index[word] = index\n",
    "    index += 1\n",
    "\n",
    "print(words1_index)\n",
    "print(words2_index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Create transition matrices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- inicializar un array de length palabras con 0s\n",
    "- llenar las que ya se tienen guardadas en su indice correspondiente y ya!! hacer append de la lista a la matriz wuuu\n",
    "/ ok necesitamos que las matrices y asi... estar tratando con todas las palabras, no solo con las actuales...\n",
    "\n",
    "con esto ponemos ok... mat1[map[i]] = 1 / total o asi... o sea aja... \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  1.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.5 0.  0.  0.  0.5]\n",
      " [0.  0.  0.  1.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  1.  0.  0. ]\n",
      " [0.  0.5 0.  0.  0.  0.5 0. ]\n",
      " [0.  0.  0.  0.  1.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0. ]]\n",
      "[[0.  0.  0.  0.  0.  0.  1. ]\n",
      " [0.  0.  0.5 0.  0.  0.5 0. ]\n",
      " [1.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  1.  0.  0. ]\n",
      " [0.  1.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  1.  0.  0. ]\n",
      " [0.  1.  0.  0.  0.  0.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "mat1 = []\n",
    "mat2 = []\n",
    "\n",
    "len1 = len(words1)\n",
    "len2 = len(words2)\n",
    "\n",
    "for word in words1:\n",
    "    list1 = [0 for i in range(len1)]\n",
    "\n",
    "    val1 = 0\n",
    "    if len(words1[word]) != 0:\n",
    "        val1 = 1 / len(words1[word])\n",
    "\n",
    "    for next_word in words1[word]:\n",
    "        next_word_index = words1_index[next_word]\n",
    "        list1[next_word_index] += val1        \n",
    "\n",
    "    mat1.append(list1)\n",
    "\n",
    "\n",
    "for word in words2:\n",
    "    list2 = [0 for i in range(len2)]\n",
    "    \n",
    "    val2 = 0\n",
    "    if len(words2[word]) != 0:\n",
    "        val2 = 1 / len(words2[word])\n",
    "\n",
    "    for next_word in words2[word]:\n",
    "        next_word_index = words2_index[next_word]\n",
    "        list2[next_word_index] += val2        \n",
    "\n",
    "    mat2.append(list2)\n",
    "\n",
    "mat1 = np.array(mat1)\n",
    "mat2 = np.array(mat2)\n",
    "\n",
    "print(mat1)\n",
    "print(mat2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A | Mat1 = \n",
      "[[0.  1.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.5 0.  0.  0.  0.5]\n",
      " [0.  0.  0.  1.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  1.  0.  0. ]\n",
      " [0.  0.5 0.  0.  0.  0.5 0. ]\n",
      " [0.  0.  0.  0.  1.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0. ]]\n",
      "\n",
      "B | Mat2 = \n",
      "[[0.  0.  0.  0.  0.  0.  1. ]\n",
      " [0.  0.  0.5 0.  0.  0.5 0. ]\n",
      " [1.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  1.  0.  0. ]\n",
      " [0.  1.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  1.  0.  0. ]\n",
      " [0.  1.  0.  0.  0.  0.  0. ]]\n",
      "\n",
      "BT | Transpose of Mat2 = \n",
      "[[0.  0.  1.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  1.  0.  1. ]\n",
      " [0.  0.5 0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  1.  0.  1.  0. ]\n",
      " [0.  0.5 0.  0.  0.  0.  0. ]\n",
      " [1.  0.  0.  0.  0.  0.  0. ]]\n",
      "\n",
      "C = [[0.   0.   0.   1.   0.   0.   0.  ]\n",
      " [0.   0.5  0.   0.   0.   0.5  0.  ]\n",
      " [0.   0.   0.25 0.   0.   0.   0.25]\n",
      " [0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   2.   0.   0.  ]\n",
      " [0.   0.   0.25 0.   0.   0.   0.25]\n",
      " [0.   1.   0.   0.   0.   0.   0.  ]]\n",
      "\n",
      "Prod int = 2.75\n",
      "\n",
      "Norm A | Norm Mat1 = 2.2361\n",
      "\n",
      "Norm B | Norm Mat2 = 2.5495\n",
      "\n",
      "Cosine angle = 0.4824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BT = mat2.transpose()\n",
    "C = np.matmul(BT, mat1)\n",
    "prod_int = np.trace(C)\n",
    "\n",
    "norm_A = math.sqrt(np.trace(np.matmul(mat1.transpose(), mat1)))\n",
    "norm_B = math.sqrt(np.trace(np.matmul(mat2.transpose(), mat2)))\n",
    "\n",
    "cos_ang = prod_int / (norm_A * norm_B)\n",
    "\n",
    "\n",
    "print('A | Mat1 = \\n' + str(mat1) + '\\n')\n",
    "print('B | Mat2 = \\n' + str(mat2) + '\\n')\n",
    "print('BT | Transpose of Mat2 = \\n' + str(BT) + '\\n')\n",
    "print('C = ' + str(C) + '\\n')\n",
    "print('Prod int = ' + str(round(prod_int, 4)) + '\\n')\n",
    "print('Norm A | Norm Mat1 = ' + str(round(norm_A, 4)) + '\\n')\n",
    "print('Norm B | Norm Mat2 = ' + str(round(norm_B, 4)) + '\\n')\n",
    "print('Cosine angle = ' + str(round(cos_ang, 4)) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
